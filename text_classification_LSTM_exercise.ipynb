{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1222e316-a03e-4b08-b24c-72ba0c4fa35d",
   "metadata": {},
   "source": [
    "### Text classification using LSTM\r\n",
    "Objective:ll create a simple LSTM model using PyTorch to perform text classification on a dataset of short phrase`.Stepsd to:\r\n",
    "\r\n",
    "- Create a vocabulary to represent words as indices.\r\n",
    "- Tokenize, encode, and pad the phrases.\r\n",
    "- Convert the phrases and categories to PyTorch tensors.\r\n",
    "- Instantiate the LSTM model with the vocabulary size, embedding dimensions, hidden dimensions, and output dimensions.\r\n",
    "- Define the loss function and optimizer.\r\n",
    "- Train the model for a number of epochs.\r\n",
    "- Test the model on new phrases and print the category predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c068a0d9-da09-4302-beeb-0428efd9f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d94ab2a-4d44-4b6b-a133-6851ea6b80b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrases (textual data) and their category labels (0 for sports, 1 for technology, 2 for food)\n",
    "# Note: this data is extremely less for realistically training an LSTM model. Feel free to use\n",
    "# a relevant data source or create your own dummy data for this exercise.\n",
    "phrases = [\"great goal scored\", \"amazing touchdown\", \"new phone release\", \"latest laptop model\", \"tasty pizza\", \"delicious burger\"]\n",
    "categories = [0, 0, 1, 1, 2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198cbc4a-ab54-4d2b-89f7-85973aebe852",
   "metadata": {},
   "source": [
    "### Create a vocabulary to represent words as indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ec64c0-d83e-4aed-9f73-37b0cabe181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\"<PAD>\": 0, \"great\": 1, \"goal\": 2,\n",
    "         \"scored\": 3, \"amazing\": 4, \"touchdown\": 5,\n",
    "         \"new\": 6, \"phone\": 7, \"release\": 8,\n",
    "         \"latest\": 9, \"laptop\": 10, \"model\": 11,\n",
    "         \"tasty\": 12, \"pizza\": 13, \"delicious\": 14,\n",
    "         \"burger\": 15\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde900f-4b96-4e9c-905a-484a333ddc24",
   "metadata": {},
   "source": [
    "### Tokenize, encode, and pad phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f90f8bc-4413-485f-ae0d-e26f9824be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = [[vocab[word] for word in phrase.split()] for phrase in phrases]\n",
    "max_length = max([len(phrase) for phrase in encoded])\n",
    "padded = [phrase + [vocab['<PAD>']] * (max_length - len(phrase)) for phrase in encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f58dc268-4541-40b5-8190-51378657ae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 0], [6, 7, 8], [9, 10, 11], [12, 13, 0], [14, 15, 0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261b63bf-6a9a-4e6f-ba2f-472eed38f91d",
   "metadata": {},
   "source": [
    "### Convert phrases and categories to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c6f0129-61e4-4385-a6b7-17eb0e9cfae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3],\n",
       "         [ 4,  5,  0],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13,  0],\n",
       "         [14, 15,  0]]),\n",
       " tensor([0, 0, 1, 1, 2, 2]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.LongTensor(padded)\n",
    "labels = torch.LongTensor(categories)\n",
    "inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbd2cbba-cd36-43f7-97d2-195c91534b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "class PhraseClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(PhraseClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, (hidden, _) = self.lstm(embedded)\n",
    "        logits = self.fc(hidden.squeeze(0))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bc4865-6f1c-4ee2-bb3d-a9aef2e38f8d",
   "metadata": {},
   "source": [
    "### Instantiate model and define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "383cfd54-0451-411b-9b0d-4753f7710b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PhraseClassifier(vocab_size=len(vocab), embedding_dim=10, hidden_dim=20, output_dim=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555914c3-cbce-4cad-82bb-b82eb8ba5e9e",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef26cf93-f880-428b-909b-bca6e326a342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 1.0620263814926147\n",
      "Epoch: 20, Loss: 1.0145480632781982\n",
      "Epoch: 30, Loss: 0.9610541462898254\n",
      "Epoch: 40, Loss: 0.8977944850921631\n",
      "Epoch: 50, Loss: 0.8221752643585205\n",
      "Epoch: 60, Loss: 0.7337680459022522\n",
      "Epoch: 70, Loss: 0.6349571943283081\n",
      "Epoch: 80, Loss: 0.5307366847991943\n",
      "Epoch: 90, Loss: 0.42742419242858887\n",
      "Epoch: 100, Loss: 0.33165740966796875\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    # Clear the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = model(inputs.t()).squeeze(1)\n",
    "    # if (epoch < 3): print(model(inputs.t())) \n",
    "    # Calculate the loss and perform optimization step\n",
    "    loss = criterion(predictions, labels)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(epoch % 10 == 0):\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b532f7-1f88-4ba9-ac64-1939bf1e148b",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be45d5fc-7fb3-4575-8f4f-975bf838b0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions: tensor([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Test the model on new phrases\n",
    "with torch.no_grad():\n",
    "    test_phrases = [\"incredible match\", \"newest gadget\", \"yummy cake\"]\n",
    "    encoded_test_phrases = [[vocab.get(word, vocab[\"<PAD>\"]) for word in phrase.split()] for phrase in test_phrases]\n",
    "    padded_test_phrases = [phrase + [vocab[\"<PAD>\"]] * (max_length - len(phrase)) for phrase in encoded_test_phrases]\n",
    "    test_inputs = torch.LongTensor(padded_test_phrases)\n",
    "    test_predictions = torch.argmax(model(test_inputs.t()), dim=1)\n",
    "    print(\"Test predictions:\", test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6254fee5-a6b1-4c20-a1bd-06787b0419ae",
   "metadata": {},
   "source": [
    "The results clearly indicate an overfitted model. We can improve the testing accuracy by getting more data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
